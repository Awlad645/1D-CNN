{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea2a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv(r\"D:\\Sami Sir\\cervical\\best40datarf.csv\")\n",
    "\n",
    "X = data.iloc[:, 1:].values  # Features (all columns except the first one)\n",
    "y = data.iloc[:, 0].values   # Target variable (the first column)\n",
    "\n",
    "# Step 1: Preprocess data\n",
    "# Use LabelEncoder to encode your class labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape data for 1D CNN\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce13efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 38, 64)            256       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 38, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 19, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 17, 128)           24704     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 17, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 8, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 6, 256)            98560     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 6, 256)           1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 3, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               196864    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                6450      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 362,289\n",
      "Trainable params: 361,137\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build the 1D CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))  # Adjust dropout rate as needed\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))  # Assuming 5 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "428be7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "165/165 [==============================] - 12s 42ms/step - loss: 1.4685 - accuracy: 0.4134 - val_loss: 1.5398 - val_accuracy: 0.2492\n",
      "Epoch 2/10\n",
      "165/165 [==============================] - 6s 34ms/step - loss: 1.2461 - accuracy: 0.4806 - val_loss: 1.3387 - val_accuracy: 0.4103\n",
      "Epoch 3/10\n",
      "165/165 [==============================] - 4s 25ms/step - loss: 1.1187 - accuracy: 0.5346 - val_loss: 1.0064 - val_accuracy: 0.5965\n",
      "Epoch 4/10\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 1.0199 - accuracy: 0.5771 - val_loss: 0.9305 - val_accuracy: 0.6307\n",
      "Epoch 5/10\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.9612 - accuracy: 0.5997 - val_loss: 0.8637 - val_accuracy: 0.6619\n",
      "Epoch 6/10\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.8950 - accuracy: 0.6406 - val_loss: 0.8461 - val_accuracy: 0.6649\n",
      "Epoch 7/10\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.8350 - accuracy: 0.6615 - val_loss: 0.8688 - val_accuracy: 0.6588\n",
      "Epoch 8/10\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.7919 - accuracy: 0.6750 - val_loss: 0.7583 - val_accuracy: 0.6892\n",
      "Epoch 9/10\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.7506 - accuracy: 0.7019 - val_loss: 0.7936 - val_accuracy: 0.6892\n",
      "Epoch 10/10\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.7180 - accuracy: 0.7200 - val_loss: 0.7713 - val_accuracy: 0.6983\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7713 - accuracy: 0.6983\n",
      "Test accuracy: 0.6983282566070557\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9555d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
